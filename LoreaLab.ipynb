{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Welcome to LoreaLab Repository!**\n",
        "\n",
        "In this section, you can see and check our code. This code only prototyping to see the feasibilty of implementation and need detail works also using several API to connect with database, hardware, etc.\n",
        "```\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "7O6L_PnPwPjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch #For self training AI model\n",
        "import clip #OpenAI Library for mix and match the image and text\n",
        "from PIL import Image\n",
        "import whisper #OpenAI Library for convert sound to text and work with AI\n",
        "from transformers import pipeline\n",
        "import streamlit as st\n",
        "import openai\n",
        "import speech_recognition as sr\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer #Convert text mood become \"number\" in math to be used as weighing in machine learning.\n",
        "from sklearn.neighbors import NearestNeighbors #K-Nearest Neighbors to find similarity in machine learning\n",
        "import random\n",
        "import RPi.GPIO as GPIO  # Only if using Raspberry Pi\n",
        "\n",
        "\n",
        "#Step 1: Create function to analyze image\n",
        "def analyze_image(image_path):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
        "    moods = [\"calm\", \"romantic\", \"fresh\", \"warm\", \"luxurious\", \"playful\"]\n",
        "    text_tokens = clip.tokenize(moods).to(device)\n",
        "    image_features = model.encode_image(image)\n",
        "    text_features = model.encode_text(text_tokens)\n",
        "    similarity = (image_features @ text_features.T).softmax(dim=-1)\n",
        "    best_mood = moods[similarity.argmax().item()]\n",
        "    return generate_perfume_formula(best_mood)\n",
        "\n",
        "#Step 2: Create function to analyze audio\n",
        "def analyze_audio(audio_path):\n",
        "    model = whisper.load_model(\"base\")\n",
        "    result = model.transcribe(audio_path)\n",
        "    text = result[\"text\"]\n",
        "    sentiment_model = pipeline(\"sentiment-analysis\")\n",
        "    sentiment = sentiment_model(text)[0][\"label\"]\n",
        "    return generate_perfume_formula(sentiment.lower())\n",
        "\n",
        "#Step 3: Create function to detect user by proximity sensor using Raspberry pi\n",
        "SENSOR_PIN = 4\n",
        "GPIO.setmode(GPIO.BCM)\n",
        "GPIO.setup(SENSOR_PIN, GPIO.IN)\n",
        "\n",
        "def detect_proximity():\n",
        "    \"\"\"Detect when a user is near the sensor\"\"\"\n",
        "    return GPIO.input(SENSOR_PIN) == 1  # Adjust based on sensor logic\n",
        "\n",
        "#Step 4: Create function to analyze audio\n",
        "#Dictionary for parfume formula\n",
        "perfume_dict = {\n",
        "    \"calm\": \"80% lavender, 10% musk, 10% citrus\",\n",
        "    \"romantic\": \"60% rose, 30% vanilla, 10% amber\",\n",
        "    \"fresh\": \"50% lemon, 30% mint, 20% green tea\",\n",
        "    \"warm\": \"40% sandalwood, 40% cinnamon, 20% vanilla\",\n",
        "    \"luxurious\": \"50% oud, 30% jasmine, 20% saffron\",\n",
        "    \"playful\": \"50% fruity, 30% caramel, 20% floral\"\n",
        "}\n",
        "\n",
        "\n",
        "moods = list(perfume_dict.keys()) # Data for machine learning\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(moods)  #Vectorizer  NLP\n",
        "\n",
        "knn = NearestNeighbors(n_neighbors=1, metric='cosine')\n",
        "knn.fit(X) # KNN model to find the similarities mood\n",
        "\n",
        "def generate_perfume_formula(mood):\n",
        "    if mood in perfume_dict:\n",
        "        return perfume_dict[mood]\n",
        "\n",
        "    else:\n",
        "        mood_vector = vectorizer.transform([mood]) # Transform input mood\n",
        "        nearest_idx = knn.kneighbors(mood_vector, return_distance=False)[0][0]\n",
        "        closest_mood = moods[nearest_idx]  # Find the nearest mood\n",
        "\n",
        "        # Ambil komposisi dari mood terdekat\n",
        "        base_formula = perfume_dict[closest_mood]\n",
        "\n",
        "        # Generate variasi dengan mengganti beberapa bahan\n",
        "        ingredients = base_formula.split(\", \")\n",
        "        random.shuffle(ingredients)  # Acak urutan\n",
        "        new_formula = \", \".join(ingredients)\n",
        "\n",
        "        return f\"(Auto-generated) {new_formula} (Closest match: {closest_mood})\"\n",
        "\n",
        "\n",
        "#Step 5: Create function to define formula that needed to create\n",
        "def choose_formula(concentration, volume, top, middle, base):\n",
        "    return f\"Concentration : {concentration}, Fill Option: {fill_option}, Volume: {volume}ml, Main Accord: {main_accord}, Top Notes: {top}, Middle Notes: {middle}, Base Notes: {base}\"\n",
        "\n",
        "#Step 6: Create function to create interactive voice chat based on question that we create\n",
        "def interactive_voice_chat():\n",
        "    questions = [\n",
        "        \"Do you prefer to build Eau de Parfume, Eau de Cologne, or Eau de Toilette?\", #Question for concentration\n",
        "        \"Do you want to fill the parfum in new bottle or refill? If you want to refill, don't forget to put your bottle in refill place below\", #Question for fill option\n",
        "        \"Do you want to fill in 30, 50, or 100ml?\", #Question for volume\n",
        "        \"What you want for main accords?\", #Question for accords\n",
        "        \"Do you prefer bergamot, freecia, or orange for top notes?\", #Question for top notes\n",
        "        \"Do you prefer Rose, Jasmine, or pine for middle note?\", #Question for middle notes\n",
        "        \"Do you prefer Amber, Mask, or Moses for base note?\" #Question for base notes\n",
        "\n",
        "    ]\n",
        "    recognizer = sr.Recognizer()\n",
        "    responses = []\n",
        "    with sr.Microphone() as source:\n",
        "        for question in questions:\n",
        "            st.write(question)\n",
        "            recognizer.adjust_for_ambient_noise(source)\n",
        "            audio = recognizer.listen(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio)\n",
        "                responses.append(text)\n",
        "            except sr.UnknownValueError:\n",
        "                responses.append(\"Unknown\")\n",
        "    return analyze_text_responses(responses)\n",
        "\n",
        "#Step 7: Text response analyzer\n",
        "def analyze_text_responses(responses):\n",
        "    sentiment_model = pipeline(\"sentiment-analysis\")\n",
        "    combined_text = \" \".join(responses)\n",
        "    sentiment = sentiment_model(combined_text)[0][\"label\"].lower()\n",
        "    return generate_perfume_formula(sentiment)\n",
        "\n",
        "#Step 8: Create Function for Guide user to interact with our machine\n",
        "st.title(\"Welcome to LoreaLab\")\n",
        "option = st.radio(\"Choose your prefer Method\", (\"Upload Image\", \"Select Formula\", \"Voice Interaction\"))\n",
        "\n",
        "if option == \"Upload Image\":\n",
        "    uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"png\"])\n",
        "    if uploaded_file is not None:\n",
        "        formula = analyze_image(uploaded_file)\n",
        "        st.write(\"Generated Perfume Formula:\", formula)\n",
        "\n",
        "elif option == \"Select Formula\":\n",
        "    concentration = st.selectbox(\"Choose Concentration\", [\"Eau de Cologne\", \"Eau de Toilette\", \"Eau de Parfum\"])\n",
        "    volume = st.selectbox(\"Select Volume (ml)\", 30, 50, 100)\n",
        "    fill_option = st.selectbox(\"Fresh flask or a refill of perfection?\", [\"New Bottle\", \"Refill\"])\n",
        "    main_accord = st.selectbox(\"Main accords\", [\"Sweet\", \"Synthetic\", \"Spicy\", \"Woody\", \"Jasmine\"])\n",
        "    top_note = st.selectbox(\"Top Notes\", [\"Bergamot\", \"Freecia\", \"Orange\", \"Mint\", \"Dust\"])\n",
        "    middle_note = st.selectbox(\"Middle Notes\", [\"Hellotrope\", \"Rose\", \"Jasmine\", \"Pine\", \"Gardenia\"])\n",
        "    base_note = st.selectbox(\"Base Notes\", [\"Amber\", \"Mask\", \"Moses\", \"Vanila\", \"Magnolia\"])\n",
        "    if st.button(\"Generate Formula\"):\n",
        "        formula = choose_formula(concentration, volume, top_note, middle_note, base_note)\n",
        "        st.write(\"Custom Perfume Formula:\", formula)\n",
        "\n",
        "elif option == \"Voice Interaction\":\n",
        "    st.write(\"Move closer to the machine to start interaction\"):\n",
        "    if detect_proximity() # Automatically triggers when user is near the sensor\n",
        "        formula = interactive_voice_chat()\n",
        "        st.write(\"Generated Perfume Formula:\", formula)\n"
      ],
      "metadata": {
        "id": "jlJNJOHdwOY7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}